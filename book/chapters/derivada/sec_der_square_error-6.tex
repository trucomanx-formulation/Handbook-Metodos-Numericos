
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Derivada de segundo ordem de $||\VECTOR{f}(\VECTOR{x})-\VECTOR{b}||_{\MATRIX{C}}^2$ 
}



\begin{theorem}[Valor exato:]\label{theo:der2fxbCfxb0}
Se
$\VECTOR{x}\in \mathbb{R}^N$ e 
$\VECTOR{b}\in \mathbb{R}^M$ são vetores coluna,  
$\VECTOR{f}: \mathbb{R}^{N}\rightarrow \mathbb{R}^{M}$ é uma função de valor vetorial,
$\MATRIX{C} \in \mathbb{R}^{M\times M}$ é uma matriz diagonal, e
definimos a função $e(\VECTOR{x})$ como
\begin{equation}
e(\VECTOR{x})= ||\VECTOR{f}(\VECTOR{x})-\VECTOR{b}||_{\MATRIX{C}}^2;
\end{equation}
então a \hyperref[def:hessian]{\textbf{matriz Hessiana}} $\MATRIX{H}(\VECTOR{x})$ 
de $e(\VECTOR{x})$ é igual\footnote{A demonstração pode ser vista na Prova \ref{proof:theo:der2fxbCfxb0}.} a:
\begin{equation}
\MATRIX{H}(\VECTOR{x}) = \frac{\partial}{\partial \VECTOR{x}^{\transpose}}\left(  
\frac{\partial e(\VECTOR{x}) }{\partial \VECTOR{x}} \right) = 2 \MATRIX{B}(\VECTOR{x})
+2 \MATRIX{J}(\VECTOR{x})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{x}),
\end{equation}
em que 
\begin{equation}
 \MATRIX{B}(\VECTOR{x})=
{\bigcup\limits_{n=1}^{ \rightarrow }}^{N}\left\{ \frac{\partial \MATRIX{J}(\VECTOR{x})^{\transpose} }{\partial x_{n}} \MATRIX{C} \left( \VECTOR{f}(\VECTOR{x})-\VECTOR{b}\right) \right\},
\end{equation}
e $\MATRIX{J}(\VECTOR{x})$ é a \hyperref[def:jacobian]{\textbf{matriz Jacobiana}} de $\VECTOR{f}(\VECTOR{x})$.
\end{theorem}

\begin{theorem}[Valor aproximado:]\label{theo:der2fxbCfxb0aprox}
Se 
$\VECTOR{x}\in \mathbb{R}^N$ é  
$\VECTOR{b}\in \mathbb{R}^M$ são vetores coluna,  
$\VECTOR{f}: \mathbb{R}^{N}\rightarrow \mathbb{R}^{M}$ é uma função de valor vetorial,
$\MATRIX{C} \in \mathbb{R}^{M\times M}$ é uma matriz diagonal, e 
definimos a função $e(\VECTOR{x})$ como
\begin{equation}
e(\VECTOR{x})= ||\VECTOR{f}(\VECTOR{x})-\VECTOR{b}||_{\MATRIX{C}}^2.
\end{equation}
Então, para achar uma forma aproximada da \hyperref[def:hessian]{\textbf{matriz Hessiana}} $\MATRIX{H}(\VECTOR{x})$ de $e(\VECTOR{x})$, 
podemos usar a aproximação linear de 
$\VECTOR{f}(\VECTOR{x})\approx \VECTOR{f}(\VECTOR{p}) + \MATRIX{J}(\VECTOR{p})$ $\left(\VECTOR{x}-\VECTOR{p}\right)$, 
por meio da \hyperref[def:taylor]{\textbf{série de Taylor}} 
para funções multivariáveis,
em que $\VECTOR{p}$ é um ponto fixo no domínio de $\VECTOR{f}(\VECTOR{x})$ ao redor do qual é feita  aproximação
da função $\VECTOR{f}(\VECTOR{x})$,
e $\MATRIX{J}(\VECTOR{p})$ é a \hyperref[def:jacobian]{\textbf{matriz Jacobiana}} de $\VECTOR{f}(\VECTOR{x})$ avaliada no ponto $\VECTOR{p}$.

Com essas considerações, obtemos\footnote{A demonstração pode ser vista na Prova \ref{proof:theo:der2fxbCfxb0aprox}.} o seguinte resultado,
\begin{equation}
\MATRIX{H}(\VECTOR{x}) = \frac{\partial}{\partial \VECTOR{x}^{\transpose}}\left(  
\frac{\partial e(\VECTOR{x}) }{\partial \VECTOR{x}} \right) \approx 
2 \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{p}).
\end{equation}


\end{theorem}
