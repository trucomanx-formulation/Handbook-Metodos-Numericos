\section{Provas dos teoremas}
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{myproofT}[Prova do Teorema \ref{theo:minAxbCAxb}]\label{proof:theo:minAxbCAxb}
Dados,
um vetor coluna $\VECTOR{x}\in \mathbb{R}^N$, 
um vetor coluna $\VECTOR{b}\in \mathbb{R}^M$,  
uma matriz $\MATRIX{A} \in \mathbb{R}^{M\times N}$, 
uma matriz diagonal $\MATRIX{C} \in \mathbb{R}^{M\times M}$, e 
definida a Eq. (\ref{eq:proof:minAxbCAxb0}),
\begin{equation}\label{eq:proof:minAxbCAxb0}
e(\VECTOR{x})=||\MATRIX{A}\VECTOR{x}-\VECTOR{b}||_{\MATRIX{C}}^2.
\end{equation}
Para achar o valor  $\VECTOR{\hat{x}}$ que gere o menor valor de $e(\VECTOR{\hat{x}})$, é aplicado
o critério que um ponto de inflexão pode ser achado quando 
$\frac{\partial e(\VECTOR{\hat{x}})}{\partial \VECTOR{x} }=[0~ 0~ \hdots~ 0 ]^{\transpose}$.
Assim, usando o Corolário \ref{coro:derAxbAxb2} podemos 
rescrever esta igualdade como a Eq. (\ref{eq:proof:minAxbCAxb1}),
\begin{equation}\label{eq:proof:minAxbCAxb1}
2 \MATRIX{A}^{\transpose}\MATRIX{C}\left(\MATRIX{A}\VECTOR{\hat{x}}-\VECTOR{b}\right)=[0~ 0~ \hdots~ 0 ]^{\transpose},
\end{equation}
de modo que pode ser obtido:
\begin{equation}\label{eq:proof:minAxbCAxb2}
\VECTOR{\hat{x}}=\left( \MATRIX{A}^{\transpose}\MATRIX{C}\MATRIX{A} \right)^{-1} \MATRIX{A}^{\transpose}\MATRIX{C} \VECTOR{b}.
\end{equation}
Dado que a solução é única e a função $e(\VECTOR{x})$ é sempre positiva, então
o valor de $\VECTOR{\hat{x}}$ é um mínimo.
\end{myproofT}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{myproofT}[Prova do Teorema \ref{theo:minfxbCfxb}]\label{proof:theo:minfxbCfxb}
Dados,
um vetor coluna $\VECTOR{x}\in \mathbb{R}^N$, 
um vetor coluna $\VECTOR{b}\in \mathbb{R}^M$,  
uma função $\VECTOR{f}:\mathbb{R}^{N} \rightarrow \mathbb{R}^{M}$, 
uma matriz diagonal $\MATRIX{C} \in \mathbb{R}^{M\times M}$, e 
definida a Eq. (\ref{eq:proof:minfxbCfxb0}),
\begin{equation}\label{eq:proof:minfxbCfxb0}
e(\VECTOR{x})=||\VECTOR{f}(\VECTOR{x})-\VECTOR{b}||_{\MATRIX{C}}^2.
\end{equation}
Para achar o valor  $\VECTOR{\hat{x}}$ que gere o menor valor de $e(\VECTOR{\hat{x}})$, é aplicado
o critério que um ponto de inflexão pode ser achado quando 
$\frac{\partial e(\VECTOR{\hat{x}})}{\partial \VECTOR{x} }=[0~ 0~ \hdots~ 0 ]^{\transpose}$.
Assim, usando o Teorema \ref{theo:derfxbCfxb} podemos 
rescrever esta igualdade como a Eq. (\ref{eq:proof:minfxbCfxb1}),
\begin{equation}\label{eq:proof:minfxbCfxb1}
2 \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C}\left[\MATRIX{J}(\VECTOR{p})\left(\VECTOR{\hat{x}} - \VECTOR{p}\right)-\left(\VECTOR{b}-\VECTOR{f}(\VECTOR{p})\right)\right] \approx
\frac{\partial e(\VECTOR{\hat{x}})}{\partial \VECTOR{x} }=[0~ 0~ \hdots~ 0 ]^{\transpose},
\end{equation}
de modo que pode ser aproximado $\VECTOR{\hat{x}}$ como:
\begin{equation}\label{eq:proof:minfxbCfxb2}
\VECTOR{\hat{x}} \approx \VECTOR{p} +
\left[ \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{p}) \right]^{-1}
\MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \left(\VECTOR{b}-\VECTOR{f}(\VECTOR{p})\right).
\end{equation}
Assim, quanto mais próximo seja $\VECTOR{\hat{x}}$ ao valor escolhido $\VECTOR{p}$;
a Eq. (\ref{eq:proof:minfxbCfxb2}) fica mais próximo a uma igualdade e
$\left[ \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{p}) \right]^{-1} \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \left(\VECTOR{b}-\VECTOR{f}(\VECTOR{p})\right) \approx 0$. 
Isto implica duas possibilidades, a primeira é que $\VECTOR{b} \approx \VECTOR{f}(\VECTOR{p})$,
que é um mínimo absoluto de $e(\VECTOR{x})$,
e a segunda que $\MATRIX{J}(\VECTOR{p}) \approx 0$

Assim, um bom critério para procurar um mínimo ou máximo é seguir a seguinte 
equação iterativa,
\begin{equation}\label{eq:proof:minfxbCfxb3}
\VECTOR{p}_{k} \leftarrow \VECTOR{p}_{k-1} +
\left[ \MATRIX{J}(\VECTOR{p}_{k-1})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{p}_{k-1}) \right]^{-1}
\MATRIX{J}(\VECTOR{p}_{k-1})^{\transpose}\MATRIX{C} \left(\VECTOR{b}-\VECTOR{f}(\VECTOR{p}_{k-1})\right),
\end{equation}
iniciando desde um $\VECTOR{p}_{0}$ qualquer, ate que $\VECTOR{p}_{k}$ seja muito próximo a $\VECTOR{p}_{k-1}$,
onde se declara que $\VECTOR{\hat{x}} \approx \VECTOR{p}_{k}$; porem deve ser corroborado
que esse ponto tratasse de um máximo ou mínimo usando algum método, por exemplo estudando o comportamento 
de $e(\VECTOR{x})$ ou analisando a matriz hessiana de $e(\VECTOR{x})$ avaliada em $\VECTOR{\hat{x}}$.
\end{myproofT}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{myproofT}[Prova do Teorema \ref{theo:minfxbCfxbaxqaxq}]\label{proof:theo:minfxbCfxbaxqd}
Dados,
um escalar $\alpha\in \mathbb{R}$,
um vetor coluna $\VECTOR{x}\in \mathbb{R}^N$, 
um vetor coluna $\VECTOR{q}\in \mathbb{R}^N$, 
um vetor coluna $\VECTOR{b}\in \mathbb{R}^M$,  
uma função $\VECTOR{f}:\mathbb{R}^{N} \rightarrow \mathbb{R}^{M}$, 
uma matriz diagonal $\MATRIX{C} \in \mathbb{R}^{M\times M}$,
uma matriz diagonal $\MATRIX{D} \in \mathbb{R}^{N\times N}$, e 
definida a Eq. (\ref{eq:proof:minfxbCfxbaxqd0}),
\begin{equation}\label{eq:proof:minfxbCfxbaxqd0}
e(\VECTOR{x})=||\VECTOR{f}(\VECTOR{x})-\VECTOR{b}||_{\MATRIX{C}}^2+\alpha||\VECTOR{x}-\VECTOR{q}||_{\MATRIX{D}}^2.
\end{equation}
Para achar o valor  $\VECTOR{\hat{x}}$ que gere o menor valor de $e(\VECTOR{\hat{x}})$, é aplicado
o critério que um mínimo ou máximo pode ser achado quando 
$\frac{\partial e(\VECTOR{\hat{x}})}{\partial \VECTOR{x} }=[0~ 0~ \hdots~ 0 ]^{\transpose}$.
Assim, usando o Teorema \ref{theo:derfxbCfxbxqDxq} podemos 
rescrever esta igualdade como a Eq. (\ref{eq:proof:minfxbCfxbaxqd1}),
\begin{equation}\label{eq:proof:minfxbCfxbaxqd1}
2 \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C}\left\{\MATRIX{J}(\VECTOR{p})\left[\VECTOR{\hat{x}} - \VECTOR{p}\right]-\left[\VECTOR{b}-\VECTOR{f}(\VECTOR{p})\right]\right\} 
+2\alpha\MATRIX{D} [\VECTOR{x} -\VECTOR{q}] \approx
\frac{\partial e(\VECTOR{\hat{x}})}{\partial \VECTOR{x} }=[0~ 0~ \hdots~ 0 ]^{\transpose},
\end{equation}
de modo que pode ser aproximado $\VECTOR{\hat{x}}$ como:
\begin{equation}\label{eq:proof:minfxbCfxbaxqd2}
\VECTOR{\hat{x}} \approx \VECTOR{p} +
\left[ \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{p})+\alpha \MATRIX{D} \right]^{-1}
\left\{ \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \left[\VECTOR{b}-\VECTOR{f}(\VECTOR{p})\right]-\alpha\MATRIX{D}[\VECTOR{p}-\VECTOR{q}]\right\}.
\end{equation}
Assim, quanto mais próximo seja a $\VECTOR{\hat{x}}$ o valor escolhido $\VECTOR{p}$, 
a Eq. (\ref{eq:proof:minfxbCfxbaxqd2}) fica mais próximo a uma igualdade. Por outro lado,
a equação nos indica que dado um ponto  $\VECTOR{p}$ qualquer,
$\VECTOR{p} +
\left[ \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{p})+\alpha \MATRIX{D} \right]^{-1}
\left\{ \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \left[\VECTOR{b}-\VECTOR{f}(\VECTOR{p})\right]-\alpha\MATRIX{D}[\VECTOR{p}-\VECTOR{q}]\right\}$
é um ponto próximo de $\VECTOR{p}$  na direção de um mínimo ou máximo de $ e(\VECTOR{x})$.
Assim, um bom critério para procurar um mínimo ou máximo é seguir a seguinte 
equação iterativa,
\begin{equation}\label{eq:proof:minfxbCfxbaxqd3}
 \VECTOR{p}_{k} \leftarrow \VECTOR{p}_{k-1} +
\left[ \MATRIX{J}(\VECTOR{p}_{k-1})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{p}_{k-1})+\alpha \MATRIX{D} \right]^{-1}
\left\{ \MATRIX{J}(\VECTOR{p}_{k-1})^{\transpose}\MATRIX{C} \left[\VECTOR{b}-\VECTOR{f}(\VECTOR{p}_{k-1})\right]-\alpha\MATRIX{D}[\VECTOR{p}_{k-1}-\VECTOR{q}]\right\},
\end{equation}
iniciando desde um $\VECTOR{p}_{0}$ qualquer, ate que $\VECTOR{p}_{k}$ seja muito próximo a $\VECTOR{p}_{k-1}$,
onde se declara que $\VECTOR{\hat{x}} \approx \VECTOR{p}_{k}$; porem deve ser corroborado
que esse ponto tratasse de um máximo ou mínimo usando algum método, por exemplo estudando o comportamento 
de $e(\VECTOR{x})$ ou analisando a matriz hessiana de $e(\VECTOR{x})$ avaliada em $\VECTOR{\hat{x}}$.
\end{myproofT}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{myproofT}[Prova do Teorema \ref{theo:minfxbCfxbaxax}]\label{proof:theo:minfxbCfxbaxd}
Dados,
um escalar $\alpha\in \mathbb{R}$,
um vetor coluna $\VECTOR{x}\in \mathbb{R}^N$, 
um vetor coluna $\VECTOR{b}\in \mathbb{R}^M$,  
uma função $\VECTOR{f}:\mathbb{R}^{N} \rightarrow \mathbb{R}^{M}$, 
uma matriz diagonal $\MATRIX{C} \in \mathbb{R}^{M\times M}$,
uma matriz diagonal $\MATRIX{D} \in \mathbb{R}^{N\times N}$, e 
definida a Eq. (\ref{eq:proof:minfxbCfxbaxd0}),
\begin{equation}\label{eq:proof:minfxbCfxbaxd0}
e(\VECTOR{x})=||\VECTOR{f}(\VECTOR{x})-\VECTOR{b}||_{\MATRIX{C}}^2+\alpha||\VECTOR{x}||_{\MATRIX{D}}^2.
\end{equation}
Para achar o valor  $\VECTOR{\hat{x}}$ que gere o menor valor de $e(\VECTOR{\hat{x}})$, é aplicado
o critério que um mínimo ou máximo pode ser achado quando 
$\frac{\partial e(\VECTOR{\hat{x}})}{\partial \VECTOR{x} }=[0~ 0~ \hdots~ 0 ]^{\transpose}$.
Assim, usando a Prova \ref{proof:theo:minfxbCfxbaxqd} para o caso de $\VECTOR{q}=0$, sabemos que 
um bom critério para procurar um mínimo ou máximo é seguir a seguinte 
equação iterativa,
\begin{equation}\label{eq:proof:minfxbCfxbaxd3}
 \VECTOR{p}_{k} \leftarrow \VECTOR{p}_{k-1} +
\left[ \MATRIX{J}(\VECTOR{p}_{k-1})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{p}_{k-1})+\alpha \MATRIX{D} \right]^{-1}
\left\{ \MATRIX{J}(\VECTOR{p}_{k-1})^{\transpose}\MATRIX{C} \left[\VECTOR{b}-\VECTOR{f}(\VECTOR{p}_{k-1})\right]-\alpha\MATRIX{D}\VECTOR{p}_{k-1}\right\},
\end{equation}
iniciando desde um $\VECTOR{p}_{0}$ qualquer, ate que $\VECTOR{p}_{k}$ seja muito próximo a $\VECTOR{p}_{k-1}$,
onde se declara que $\VECTOR{\hat{x}} \approx \VECTOR{p}_{k}$; porem deve ser corroborado
que esse ponto tratasse de um máximo ou mínimo usando algum método, por exemplo estudando o comportamento 
de $e(\VECTOR{x})$ ou analisando a matriz hessiana de $e(\VECTOR{x})$ avaliada em $\VECTOR{\hat{x}}$.
\end{myproofT}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{myproofT}[Prova do Teorema \ref{theo:minfxbCfxbaxoaxo}]\label{proof:theo:minfxbCfxbaxod}
Dados,
um escalar $\alpha\in \mathbb{R}$,
um vetor coluna $\VECTOR{x}\in \mathbb{R}^N$, 
um vetor coluna $\VECTOR{x}_{last}\in \mathbb{R}^N$ (constante), 
um vetor coluna $\VECTOR{b}\in \mathbb{R}^M$,  
uma função $\VECTOR{f}:\mathbb{R}^{N} \rightarrow \mathbb{R}^{M}$, 
uma matriz diagonal $\MATRIX{C} \in \mathbb{R}^{M\times M}$,
uma matriz diagonal $\MATRIX{D} \in \mathbb{R}^{N\times N}$, e 
definida a Eq. (\ref{eq:proof:minfxbCfxbaxod0}),
\begin{equation}\label{eq:proof:minfxbCfxbaxod0}
e(\VECTOR{x})=||\VECTOR{f}(\VECTOR{x})-\VECTOR{b}||_{\MATRIX{C}}^2+\alpha||\VECTOR{x}-\VECTOR{x}_{last}||_{\MATRIX{D}}^2.
\end{equation}
Para achar o valor  $\VECTOR{\hat{x}}$ que gere o menor valor de $e(\VECTOR{\hat{x}})$, é aplicado
o critério que um mínimo ou máximo pode ser achado quando 
$\frac{\partial e(\VECTOR{\hat{x}})}{\partial \VECTOR{x} }=[0~ 0~ \hdots~ 0 ]^{\transpose}$.
Assim, usando o Teorema \ref{theo:derfxbCfxbxqDxq} podemos 
rescrever esta igualdade como a Eq. (\ref{eq:proof:minfxbCfxbaxod1}),
\begin{equation}\label{eq:proof:minfxbCfxbaxod1}
2 \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C}\left\{\MATRIX{J}(\VECTOR{p})\left[\VECTOR{\hat{x}} - \VECTOR{p}\right]-\left[\VECTOR{b}-\VECTOR{f}(\VECTOR{p})\right]\right\} 
+2\alpha\MATRIX{D} [\VECTOR{x} -\VECTOR{x}_{last}] \approx
\frac{\partial e(\VECTOR{\hat{x}})}{\partial \VECTOR{x} }=[0~ 0~ \hdots~ 0 ]^{\transpose},
\end{equation}
de modo que pode ser aproximado $\VECTOR{\hat{x}}$ como:
\begin{equation}\label{eq:proof:minfxbCfxbaxod2}
\VECTOR{\hat{x}} \approx \VECTOR{p} +
\left[ \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{p})+\alpha \MATRIX{D} \right]^{-1}
\left\{ \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \left[\VECTOR{b}-\VECTOR{f}(\VECTOR{p})\right]-\alpha\MATRIX{D}[\VECTOR{p}-\VECTOR{x}_{last}]\right\}.
\end{equation}
Assim, quanto mais próximo seja a $\VECTOR{\hat{x}}$ o valor escolhido $\VECTOR{p}$, 
a Eq. (\ref{eq:proof:minfxbCfxbaxod2}) fica mais próximo a uma igualdade. Por outro lado,
a equação nos indica que dado um ponto  $\VECTOR{p}$ qualquer,
$\VECTOR{p} +
\left[ \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{p})+\alpha \MATRIX{D} \right]^{-1}
\left\{ \MATRIX{J}(\VECTOR{p})^{\transpose}\MATRIX{C} \left[\VECTOR{b}-\VECTOR{f}(\VECTOR{p})\right]-\alpha\MATRIX{D}[\VECTOR{p}-\VECTOR{x}_{last}]\right\}$
é um ponto próximo de $\VECTOR{p}$  na direção de um mínimo ou máximo de $ e(\VECTOR{x})$.
Assim, igualando $\VECTOR{p}_{k}=\VECTOR{x}_{last}$,  um bom critério para procurar um mínimo ou máximo é seguir a seguinte 
equação iterativa,
\begin{equation}\label{eq:proof:minfxbCfxbaxod3}
 \VECTOR{p}_{k} \leftarrow \VECTOR{p}_{k-1} +
\left[ \MATRIX{J}(\VECTOR{p}_{k-1})^{\transpose}\MATRIX{C} \MATRIX{J}(\VECTOR{p}_{k-1})+\alpha \MATRIX{D} \right]^{-1}
\left\{ \MATRIX{J}(\VECTOR{p}_{k-1})^{\transpose}\MATRIX{C} \left[\VECTOR{b}-\VECTOR{f}(\VECTOR{p}_{k-1})\right] \right\},
\end{equation}
iniciando desde um $\VECTOR{p}_{0}$ qualquer, ate que $\VECTOR{p}_{k}$ seja muito próximo a $\VECTOR{p}_{k-1}$,
onde se declara que $\VECTOR{\hat{x}} \approx \VECTOR{p}_{k}$; porem deve ser corroborado
que esse ponto tratasse de um máximo ou mínimo usando algum método, por exemplo estudando o comportamento 
de $e(\VECTOR{x})$ ou analisando a matriz hessiana de $e(\VECTOR{x})$ avaliada em $\VECTOR{\hat{x}}$.
\end{myproofT}
