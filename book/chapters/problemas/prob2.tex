\chapterimage{chapter_head_2.pdf} % Chapter heading image

\chapter{Minimização de funções com variável vetorial}

\begin{remark}
Palavras chave: 
Pseudo-inversa de Moore-Penrose,
regularização de Tikhonov,
problema inverso, 
minimização do erro quadrático. 
\end{remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Minimização de $||\mathbf{A}\mathbf{x}-\mathbf{b}||_{\mathbf{C}}^2$
}

\begin{theorem}\label{theo:minAxbCAxb}
Dados,
um vetor coluna $\mathbf{x}\in \mathbb{R}^N$, 
um vetor coluna $\mathbf{b}\in \mathbb{R}^M$,  
uma matriz $\mathbf{A} \in \mathbb{R}^{M\times N}$, 
uma matriz diagonal $\mathbf{C} \in \mathbb{R}^{M\times M}$, e 
definida a Eq. (\ref{eq:minAxbCAxb1}),
\begin{equation}\label{eq:minAxbCAxb1}
e(\mathbf{x})=||\mathbf{A}\mathbf{x}-\mathbf{b}||_{\mathbf{C}}^2.
\end{equation}
Se desejamos ter o valor $\mathbf{\hat{x}}$ que minimiza o escalar $e(\mathbf{\hat{x}})$,
devemos usar a Eq. (\ref{eq:minAxbCAxb2}),
\begin{equation}\label{eq:minAxbCAxb2}
\mathbf{\hat{x}} =
\left[ \mathbf{A}^{\transpose}\mathbf{C} \mathbf{A} \right]^{-1}\mathbf{A}^{\transpose}\mathbf{C}\mathbf{b}.
\end{equation}
Assim, o mínimo existe só sim $\mathbf{A}^{\transpose}\mathbf{C} \mathbf{A}$ tem inversa.

A demostração pode ser vista na Prova \ref{proof:theo:minAxbCAxb}.
\end{theorem}

\index{Pseudo-inversa de Moore-Penrose}
\index{Problema inverso!Linear}
\index{Minimização do erro quadrático!Linear}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Minimização de $||\mathbf{f}(\mathbf{x})-\mathbf{b}||_{\mathbf{C}}^2$
(solução iterativa)
}

\begin{theorem}\label{theo:minfxbCfxb}
Dados,
um vetor coluna $\mathbf{x}\in \mathbb{R}^N$, 
um vetor coluna $\mathbf{b}\in \mathbb{R}^M$,  
uma função $\mathbf{f}:\mathbb{R}^{N} \rightarrow \mathbb{R}^{M}$, 
uma matriz diagonal $\mathbf{C} \in \mathbb{R}^{M\times M}$, e 
definida a Eq. (\ref{eq:minfxbCfxb1}),
\begin{equation}\label{eq:minfxbCfxb1}
e(\mathbf{\hat{x}})=||\mathbf{f}(\mathbf{x})-\mathbf{b}||_{\mathbf{C}}^2.
\end{equation}
Se desejamos ter o valor $\mathbf{\hat{x}}$ que minimiza o escalar $e(\mathbf{\hat{x}})$,
este valor pode ser achado usando iterativamente a Eq. (\ref{eq:minfxbCfxb2}),
\begin{equation}\label{eq:minfxbCfxb2}
\mathbf{\hat{x}}_{k+1} \leftarrow \mathbf{\hat{x}}_k+
\left[ \mathbf{J}(\mathbf{\hat{x}}_k)^{\transpose}\mathbf{C} \mathbf{J}(\mathbf{\hat{x}}_k) \right]^{-1}
 \mathbf{J}(\mathbf{\hat{x}}_k)^{\transpose}\mathbf{C}\left[\mathbf{b}-\mathbf{f}(\mathbf{\hat{x}}_k)\right]
\end{equation}
Onde  $\mathbf{J}(\mathbf{x})$ é a matriz Jacobiana de $\mathbf{f}(\mathbf{x})$.
A busca iterativa é considerada falida quando 
$\mathbf{J}(\mathbf{\hat{x}}_k)^{\transpose}$ $\mathbf{C}$ $\mathbf{J}(\mathbf{\hat{x}}_k)$
não tem inversa.

A demostração pode ser vista na Prova \ref{proof:theo:minfxbCfxb}.
\end{theorem}

\index{Regularização! Regularização de Tikhonov}
\index{Problema inverso!Não linear}
\index{Minimização do erro quadrático!Não linear}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Minimização de $||\mathbf{f}(\mathbf{x})-\mathbf{b}||_{\mathbf{C}}^2+\alpha||\mathbf{x}||_{\mathbf{D}}^2$  
(solução iterativa)
}

\begin{theorem}\label{theo:minfxbCfxbaxax}
Sabendo que, $\mathbf{x}$ é um vetor com $N$ elementos, $\mathbf{f}(\mathbf{x})$ e 
$\mathbf{b}$ são vetores coluna de $M$ elementos sendo $\mathbf{b}$ uma constante,
$\mathbf{C}$ uma matriz diagonal de $M \times M$ e 
$\mathbf{D}$ uma matriz diagonal de $N \times N$ :
Se desejamos minimizar o valor de $E$, visto na Eq. (\ref{eq:minfxbCfxb1}), em relação a $\mathbf{x}$.
\begin{equation}\label{eq:minfxbCfxbaxax1}
E=||\mathbf{f}(\mathbf{x})-\mathbf{b}||_{\mathbf{C}}^2+\alpha||\mathbf{x}||_{\mathbf{D}}^2
\end{equation}

\begin{equation}
\mathbf{x}_{k+1}\approx \mathbf{x}_k+
\left[ \mathbf{J}(\mathbf{x}_k)^{\transpose}\mathbf{C} \mathbf{J}(\mathbf{x}_k) +\alpha\mathbf{D} \right]^{-1}
 \left[\mathbf{J}(\mathbf{x}_k)^{\transpose}\mathbf{C}\left(\mathbf{b}-\mathbf{f}(\mathbf{x}_k)\right)-\alpha\mathbf{D}\mathbf{x}\right]
\end{equation}
Onde  $\mathbf{J}(\mathbf{x})$ é a matriz Jacobiana de $\mathbf{f}(\mathbf{x})$.
\end{theorem} 

\index{Regularização! Regularização de Tikhonov}
\index{Problema inverso!Não linear}
\index{Minimização do erro quadrático}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Minimização de $||\mathbf{f}(\mathbf{x})-\mathbf{b}||_{\mathbf{C}}^2+\alpha||\mathbf{x}-\mathbf{q}||_{\mathbf{D}}^2$  
(solução iterativa)
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Minimização de $\frac{||\mathbf{f}(\mathbf{x})-\mathbf{b}||^2}{||\mathbf{b}||^2}$
$+\alpha\frac{||\mathbf{x}-\mathbf{q}||^2}{||\mathbf{q}||^2}$  
(solução iterativa)
}

\textcolor{red}{Inventado por mi ..., creo.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Minimização de $||\mathbf{f}(\mathbf{x})-\mathbf{b}||_{\mathbf{B}^{-2}}^2$
$+\alpha||\mathbf{x}-\mathbf{q}||_{\mathbf{Q}^{-2}}^2$  
(solução iterativa)
}


\textcolor{red}{Inventado por mi ..., creo Nenhun valor de $\mathbf{b}$ ou $\mathbf{q}$ pode ser zero.}


